<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Asistente de Voz</title>
</head>
<body>
    <h1>Asistente de Voz</h1>
    <button id="start">Iniciar</button>
    <button id="stop">Detener</button>
    <p id="status">Esperando...</p>
    <p><strong>Respuesta:</strong> <span id="response"></span></p>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let interval;
        const INTERVALO = 10000; // 10 segundos
        
        async function startRecording() {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            
            mediaRecorder.ondataavailable = event => {
                audioChunks.push(event.data);
            };
            
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                audioChunks = [];
                
                // Enviar a API de OpenAI Whisper (debes configurar tu API Key y endpoint)
                const formData = new FormData();
                formData.append("file", audioBlob, "audio.wav");
                formData.append("model", "whisper-1");
                
                document.getElementById("status").innerText = "Procesando...";
                try {
                    const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
                        method: "POST",
                        headers: { "Authorization": "Bearer " },
                        body: formData
                    });
                    const data = await response.json();
                    const texto = data.text;
                    obtenerRespuesta(texto);
                } catch (error) {
                    console.error("Error en la transcripción:", error);
                    document.getElementById("status").innerText = "Error en la transcripción";
                }
            };
            
            mediaRecorder.start();
            setTimeout(() => mediaRecorder.stop(), 5000); // Graba 5 segundos
        }
        
        async function obtenerRespuesta(texto) {
            try {
                const response = await fetch("https://api.openai.com/v1/chat/completions", {
                    method: "POST",
                    headers: {
                        "Authorization": "Bearer ",
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify({
                        model: "gpt-4",
                        messages: [{ role: "user", content: texto }]
                    })
                });
                const data = await response.json();
                document.getElementById("response").innerText = data.choices[0].message.content;
                document.getElementById("status").innerText = "Esperando...";
            } catch (error) {
                console.error("Error en la respuesta GPT:", error);
                document.getElementById("status").innerText = "Error en la respuesta";
            }
        }
        
        document.getElementById("start").addEventListener("click", () => {
            interval = setInterval(startRecording, INTERVALO);
            document.getElementById("status").innerText = "Escuchando...";
        });
        
        document.getElementById("stop").addEventListener("click", () => {
            clearInterval(interval);
            document.getElementById("status").innerText = "Detenido";
        });
    </script>
</body>
</html>
